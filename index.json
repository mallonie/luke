[{"content":"Background I spent some time over the last few weeks getting a start on my home network and removing the ISP provided Router from the network (putting it into modem mode), so it only passes the internet to my router and does nothing else.\nI previously had bought a UISP EdgeRouter 12P from Ubiquity, it has been a good Router so far. The documentation around EdgeOS could be better, it gives commands to run to make changes to the configuration but doesn\u0026rsquo;t always describe what each of the fields are or how they relate. Maybe this is something I should come to EdgeOS already knowing, as this seems like a bit of hardward that is intended for network specialists perhaps? I\u0026rsquo;m not sure.\nSo let\u0026rsquo;s get to the meat of this. I\u0026rsquo;ve been setting up the network with this router and a PiHole in order to have all devices on the network use this self hosted DNS so that I can block domains. I will probably document this in another post. With that setup I wanted to expand this and protect any devices that I bring out of the home e.g. phone, laptop, etc\u0026hellip;\nEdgeOS The EdgeOS system has a web interface that allows you to configure all the things, it is a decent interface and I\u0026rsquo;ve been able to work my way around it for the most part. It does have built in support for PPTP Remote Access and IPsec Site-to-Site, but I don\u0026rsquo;t know the details of these and they seem like a bit much for setting up on a phone and laptop.\nEnter WireGuard So I was aware of WireGuard as a VPN from a friend, he had done a similar setup with his network and used WireGuard. So I had a look around to see what was available if anything. Thankfully the community has provided for this: WireGuard/wireguard-vyatta-ubnt.\nThis project supplies the required .deb file to install wireguard on the ER12P using the E300 release. This has support for the ER4, ER6P and ER12. I took the chance that the ER12P and the ER12 were not so disimilar as to break the package. So far this has held true.\nInstalling WireGuard In order to install WireGuard you will need to be able to ssh onto the Router. You should be able to use the default login details or, if you created your own user and deleted the default, you should be able to use your user details.\n❯ ssh user@router _____ _ | ____|__| | __ _ ___ (c) 2010-2020 | _| / _ |/ _ |/ _ \\ Ubiquiti Networks, Inc. | |__| (_| | (_| | __/ |_____\\__._|\\__. |\\___| https://www.ubnt.com |___/ Welcome to EdgeOS By logging in, accessing, or using the Ubiquiti product, you acknowledge that you have read and understood the Ubiquiti License Agreement (available in the Web UI at, by default, http://192.168.1.1) and agree to be bound by its terms. user@router password: Linux er12p 4.9.79-UBNT #1 SMP Thu Jun 30 07:03:20 UTC 2022 mips64 Welcome to EdgeOS user@router:~$ The previously linked install guide describes what is needed in order to install and setup WireGuard on EdgeOS. I will outline some of that here. First thing we need to do is download and install the .deb package, replacing the envvar values as required:\nuser@router:~$ export RELEASE=1.0.20220627 BOARD=e300-v2 MODULE=1.0.20210914 user@router:~$ curl -OL https://github.com/WireGuard/wireguard-vyatta-ubnt/releases/download/${RELEASE}-1/${BOARD}-v${RELEASE}-v${MODULE}.deb user@router:~$ sudo dpkg -i ${BOARD}-v${RELEASE}-v${MODULE}.deb Configuring WireGuard and EdgeOS We are now installed and can configure WireGuard to allow connections from clients. These clients are identified by a private and public key pair, the public key is used as part of the configuration, which we will go through now. First let\u0026rsquo;s setup the key pair for our Router:\nuser@router:~$ wg genkey | tee /config/auth/wg.key | wg pubkey \u0026gt; /config/auth/wg.public With this keypair we can now setup the config for WireGuard in EdgeOS. We\u0026rsquo;ll need to enter the configure mode, run a few set commands and finally commit, save and exit:\nuser@router:~$ configure # Let\u0026#39;s set the address subent for the wireguard interface wg0 # The IP in the subnet is where the router will live for this subnet, in this # example that is 192.168.2.1 user@router:~$ set interfaces wireguard wg0 address 192.168.2.1/24 # This is the port wireguard is listening on user@router:~$ set interfaces wireguard wg0 listen-port 51820 user@router:~$ set interfaces wireguard wg0 route-allowed-ips true # We also need to set the private key we generated as part of this interface user@router:~$ set interfaces wireguard wg0 private-key /config/auth/wg.key # We need to allow access to the WireGuard Interface port in our Firewall, make # sure to set $RULE_NUMBER to something that does not conflict with an existing # rule or it will be over written user@router:~$ set firewall name WAN_LOCAL rule $RULE_NUMBER action accept user@router:~$ set firewall name WAN_LOCAL rule $RULE_NUMBER protocol udp user@router:~$ set firewall name WAN_LOCAL rule $RULE_NUMBER description \u0026#34;WireGuard VPN\u0026#34; user@router:~$ set firewall name WAN_LOCAL rule $RULE_NUMBER destination port 51820 # Finally let\u0026#39;s save all these changes user@router:~$ commit user@router:~$ save user@router:~$ exit Now that WireGuard is setup on the Router we should add our first client, to do this we\u0026rsquo;ll need to get the public key from a client. If you don\u0026rsquo;t already have one we\u0026rsquo;ll need to create one. I\u0026rsquo;ll work with the Android app here, we\u0026rsquo;ll create a new WireGuard tunnel:\nSo we\u0026rsquo;re creating a new Tunnel with the name home-network, creating a Private and Public key, setting the IP Address that this client will have 192.168.2.100/32 and if you have your own DNS Server, such as a pi-hole you can set the IP address for that in here. Next you will want to copy the Public key and create an entry for this in your Router config, this can be done as follows:\nuser@router:~$ configure # Now we\u0026#39;re going to add our first client device. This device will be able # to connet to the internal network from outside by establishing a VPN connection # to the Public IP with the above listen-port. Replace $PUBLIC_KEY_ID with the # public key for your client device e.g. kaxZYUOQZVPpu/rhiUK0Rc2L3DWGld7omTu6ZhOGk3Y= user@router:~$ set interfaces wireguard wg0 peer $PUBLIC_KEY_ID description \u0026#34;My Phone when outside\u0026#34; user@router:~$ set interfaces wireguard wg0 peer $PUBLIC_KEY_ID allowed-ips 192.168.2.100/32 # And save changes user@router:~$ commit user@router:~$ save user@router:~$ exit Finally on our client device we need to setup a Peer which will be the Router. For this we\u0026rsquo;ll need the Public IP (or a domain if you have one associated with your public ip) and the Port we\u0026rsquo;ve setup WireGuard to use.\nSo enter the public key you generated earlier when setting up the router: /config/auth/wg.public Then enter the Public IP (or domain) and Port in the Endpoint field and finally set the Allowed IPs to the value you would like, if you want all traffic to run through your home network set this value to 0.0.0.0/0. You can also have IPv6 address run through this by adding , ::/0 to the field. Now all traffic will go through this connection. However you could limit this, if you instead only want traffic local to your home network to go through you can set this to a range that encompases this e.g. 192.168.0.0/16, now everything else will use your devices public connection for anything outside of this range.\nYou can get pretty complex with AllowedIPs and this website will help you to calculate the setting if you need more than a simple range.\nConclusion This is a great setup if you want to have access to your home-network while out and about. I\u0026rsquo;ve been using it now for few weeks and having this enabled and my DNS queries running thought the pi-hole, reducing the ads and tracking that generally follow you around the internet has been great. It\u0026rsquo;s also really useful to be able to access devices at home if needed, so far I have this on my phone, but I will be setting it up on my Laptop. So while I generally do not go out and use my laptop, with this setup I can see myself being a bit more likely to do that.\nI hope this has been of use, it\u0026rsquo;s good to have it documented here for myself.\n","permalink":"https://luke.mallon.ie/posts/2022-09/wireguard-and-edgeos/","summary":"Background I spent some time over the last few weeks getting a start on my home network and removing the ISP provided Router from the network (putting it into modem mode), so it only passes the internet to my router and does nothing else.\nI previously had bought a UISP EdgeRouter 12P from Ubiquity, it has been a good Router so far. The documentation around EdgeOS could be better, it gives commands to run to make changes to the configuration but doesn\u0026rsquo;t always describe what each of the fields are or how they relate.","title":"WireGuard and EdgeOS"},{"content":"For the last 7 or 8 years I\u0026rsquo;ve been using the Linux terminal password manager Pass. I find this to be very easy to use and it fits in nicely with my workflow. I have combined this with some other software that helps in using this across devices.\nWhat you\u0026rsquo;ll need:\nGPG and a PGP Key, I won\u0026rsquo;t cover setting these up Pass git tomb Make sure to check out the Pass website, it lists many plugins and clients that you can use.\nPass Setting up Pass is fairly simple. See the installation docs for your OS to get it installed and then you would run pass init [gpg-key-id], where [gpg-key-id] is an ID for a PGP key you have full access to, this sets up a new password store located in ${HOME}/.password-store. If you then run pass you will get some output similar to the following:\n❯ pass init \u0026#34;Luke Mallon \u0026lt;luke@mallon.ie\u0026gt;\u0026#34; Password store initialized for Luke Mallon \u0026lt;luke@mallon.ie\u0026gt; ❯ pass Password Store Congratulation you now have a password manager setup. Let\u0026rsquo;s add our first password, you can do that with the following command pass generate [name of file] [length of password], that will look something like this:\n❯ pass generate luke 100 The generated password for luke is: 512XKaSods/0Y8(za\u0026#34;=k`WH#ABfHrVG.(^;MW/Wvb=HVay,swJ[tW\u0026#39;IfDexL\u0026#34;yA]\u0026amp;~-Mp6T1Ek_..{B0DPX|VkLZH$P0HrMcVdIy Then if we run pass again we\u0026rsquo;ll see this file listed:\n❯ pass Password Store └── luke Now you can work with passwords on one machine, to view your password type pass [path-to-password] e.g.:\n❯ pass luke 512XKaSods/0Y8(za\u0026#34;=k`WH#ABfHrVG.(^;MW/Wvb=HVay,swJ[tW\u0026#39;IfDexL\u0026#34;yA]\u0026amp;~-Mp6T1Ek_..{B0DPX|VkLZH$P0HrMcVdIy Sharing Now in order to be able to use these passwords across devices you\u0026rsquo;ll want to sync it in some way. Pass comes with built in support for git so you can use that with a host like github.com, gitlab.com or any other git host out there, you could even host your own with a light weight git server like gitea or charm_ SoftServe. I\u0026rsquo;ve set up mine on keybase (see the docs for how to).\nUse the following command to enable git for your password store:\n❯ pass git init Initialized empty Git repository in /home/nalum/.password-store/.git/ [main (root-commit) d1200ce] Add current contents of password store. 2 files changed, 1 insertion(+) create mode 100644 .gpg-id create mode 100644 luke.gpg [main 199756e] Configure git repository for gpg file diff. 1 file changed, 1 insertion(+) create mode 100644 .gitattributes You can then setup your remote with pass git remote add origin [git url to host repo] e.g.\n❯ pass git remote -v ❯ pass git remote add origin keybase://private/nalum/testing ❯ pass git remote -v origin keybase://private/nalum/testing (fetch) origin keybase://private/nalum/testing (push) With that setup you can now push your passwords and pull them down on another device.\nTomb The last thing we\u0026rsquo;ll look at is setting up Tomb with pass-tomb. This is an extention to the pass cli that adds some extra functionality to it. There are a number of ways to install which I\u0026rsquo;ll leave for you. Once installed you can see the details by running man pass-tomb.\nSo in order to entomb our password store we\u0026rsquo;re going to need to move the password store from it\u0026rsquo;s current location e.g. mv ~/.password-store ~/.password-store.bak, now we need to create the tomb, which we can do as follows:\n❯ pass tomb \u0026#34;Luke Mallon \u0026lt;luke@mallon.ie\u0026gt;\u0026#34; (*) Your password tomb has been created and opened in /home/nalum/.password. (*) Password store initialized for Luke, Mallon, \u0026lt;luke@mallon.ie\u0026gt; . Your tomb is: /home/nalum/.password.tomb . Your tomb key is: /home/nalum/.password.key.tomb . You can now use pass as usual. . When finished, close the password tomb using \u0026#39;pass close\u0026#39;. Now if we list the contents of the directory we\u0026rsquo;ll see the following:\n❯ ls -lah ~/.password-store total 30K drwxr-xr-x 3 nalum nalum 1.0K Sep 5 14:35 . drwx------ 129 nalum nalum 12K Sep 5 14:47 .. -rw------- 1 nalum nalum 29 Sep 5 14:35 .gpg-id -rw------- 1 nalum nalum 6 Sep 5 14:35 .host -rw------- 1 nalum nalum 11 Sep 5 14:35 .last drwx------ 2 nalum nalum 12K Sep 5 14:35 lost+found -rw------- 1 nalum nalum 11 Sep 5 14:35 .tty -rw------- 1 nalum nalum 5 Sep 5 14:35 .uid We\u0026rsquo;ll want to copy the contents of our moved Pass directory into this newly created one e.g. mv ~/.password-store.bak/* ~/.password-store and then we can work with Pass as normal, running pass open and pass close to open and close the tomb.\n❯ pass close (*) Your password tomb has been closed. . Your passwords remain present in /home/nalum/.password.tomb. ❯ pass open (*) Your password tomb has been opened in /home/nalum/.password-store/. . You can now use pass as usual. . When finished, close the password tomb using \u0026#39;pass close\u0026#39;. You can also setup a timer (if you are using a linux distribution with systemd) so that your password tomb closes automatically e.g. pass open -t 10m this will close the tomb after 10 minutes, it also updates a file ~/.password-store/.timer with this timing information:\n❯ pass open -t 10m (*) Your password tomb has been opened in /home/nalum/.password-store/. . You can now use pass as usual. . This password store will be closed in 10m ❯ cat ~/.password-store/.timer 10m Conclusion Now we have a password manager that is owned and maintained by only you. Set up in a git repostory that you can push to a hosting provider like github/gitlab/keybase or you can self host with gitea/charm_ softserve. It\u0026rsquo;s encrypted using your PGP Key which you will either need to install on all devices that you\u0026rsquo;ll want to decrypt the passwords with or can be setup on a Yubikey (or similar device) allowing you to have your private keys locked away on a device that is easily moved around and not requiring you to have duplicates of your private key on multiple devices.\nIf there is interest I\u0026rsquo;ll go over what my PGP key set up is and also go over the setup of clients (Android Password Store, passff) that I use with Pass.\n","permalink":"https://luke.mallon.ie/posts/2022-09/passwords/","summary":"For the last 7 or 8 years I\u0026rsquo;ve been using the Linux terminal password manager Pass. I find this to be very easy to use and it fits in nicely with my workflow. I have combined this with some other software that helps in using this across devices.\nWhat you\u0026rsquo;ll need:\nGPG and a PGP Key, I won\u0026rsquo;t cover setting these up Pass git tomb Make sure to check out the Pass website, it lists many plugins and clients that you can use.","title":"Passwords"},{"content":" Originally post to hackmd.io\nThis article covers getting a local Kind cluster setup with Flux and the self hosted git server Soft Serve.\nRequirements You will need to have the following installed:\ndocker installation kubectl installation kustomize installation flux installation kind installation soft installation Assumptions I am assuming the following things:\nRunning on Linux Familiar with: Docker YAML Git Kind kubectl Let\u0026rsquo;s get Started We need to run two copies of Soft Serve in order to be able to access and configure the software.\nDocker Run Soft Serve We\u0026rsquo;re going to start a local copy of Soft Serve in preparation for running a copy within the Kind cluster. Let\u0026rsquo;s assume that your Flux repository is located in /home/nalum/code/flux. You will want to setup a new environment variable: export PATH_TO_CODE=\u0026quot;/home/nalum/code\u0026quot;. This will be used to mount your local code to both the local copy and the copy running in the Kind cluster.\nLet\u0026rsquo;s get a running instance of Soft Serve going with Docker:\n❯ docker run -d \\ --name=soft-serve \\ --volume=${PATH_TO_CODE}:/soft-serve \\ --publish=23231:23231 \\ --restart=unless-stopped \\ --user=$(id -u):$(id -g) \\ --add-host=host.docker.internal:host-gateway \\ charmcli/soft-serve:latest This will start the container and then create a few directories that are used by Soft Serve as follows:\n❯ cd ${PATH_TO_CODE} ❯ tree -d -L 1 . ├── flux ├── repos # Created by Soft Serve └── ssh # Created by Soft Serve You should also be able to ssh to the Docker Soft Serve:\n❯ ssh localhost -p 23231 And you should be presented with a TUI looking something like this:\nAt this point we have the basics of what we need. You will want to clone the configuration repository from Soft Serve:\n❯ git clone ssh://localhost:23231/config Cloning into \u0026#39;config\u0026#39;... remote: Enumerating objects: 38, done. remote: Counting objects: 100% (38/38), done. remote: Compressing objects: 100% (38/38), done. remote: Total 38 (delta 11), reused 0 (delta 0), pack-reused 0 Receiving objects: 100% (38/38), 11.98 KiB | 5.99 MiB/s, done. Resolving deltas: 100% (11/11), done. You can now configure (we\u0026rsquo;ll get to this later) Soft Serve to be ready for when it\u0026rsquo;s deployed on the Kind cluster. The configuration is done with YAML and the following is the starting config created by running the software:\n# The name of the server to show in the TUI. name: Soft Serve # The host and port to display in the TUI. You may want to change this if your # server is accessible from a different host and/or port that what it\u0026#39;s # actually listening on (for example, if it\u0026#39;s behind a reverse proxy). host: localhost port: 23231 # Access level for anonymous users. Options are: read-write, read-only and # no-access. anon-access: read-write # You can grant read-only access to users without private keys. Any password # will be accepted. allow-keyless: false # Customize repo display in the menu. Only repos in this list will appear in # the TUI. repos: - name: Home repo: config private: true note: \u0026#34;Configuration and content repo for this server\u0026#34; # users: # - name: Admin # admin: true # public-keys: # - KEY TEXT # - name: Example User # collab-repos: # - REPO # public-keys: # - KEY TEXT Setting Up Kind For the Kind cluster we need to mount the $PATH_TO_CODE onto one or all of the nodes running in the cluster. The following config will setup a cluster one node and the path mounted for use by containers deployed on that node:\nkind: Cluster apiVersion: kind.x-k8s.io/v1alpha4 name: dev nodes: - role: control-plane extraMounts: - hostPath: /home/nalum/code # Same value that is in $PATH_TO_CODE containerPath: /soft-serve readOnly: false selinuxRelabel: false propagation: None Get your cluster up by running the following (this will change your kubectl context):\n❯ kind create cluster --config dev-config.yaml Creating cluster \u0026#34;dev\u0026#34; ... ✓ Ensuring node image (kindest/node:v1.21.1) 🖼 ✓ Preparing nodes 📦 ✓ Writing configuration 📜 ✓ Starting control-plane 🕹️ ✓ Installing CNI 🔌 ✓ Installing StorageClass 💾 Set kubectl context to \u0026#34;kind-dev\u0026#34; You can now use your cluster with: kubectl cluster-info --context kind-dev Have a question, bug, or feature request? Let us know! https://kind.sigs.k8s.io/#community 🙂 Kind Run Soft Serve Now that we\u0026rsquo;ve got the a default setup of Soft Serve and the Kind cluster running it\u0026rsquo;s time to run Soft Serve on the Kind cluster. We will define a Namespace, a Service and a Deployment to get this running on the Kind cluster.\nThe Namespace:\napiversion: v1 kind: namespace metadata: name: soft-serve labels: app: soft-serve The Service:\napiversion: v1 kind: service metadata: name: git namespace: soft-serve labels: app: soft-serve spec: type: clusterip selector: app: soft-serve ports: - name: ssh port: 23231 targetPort: 23231 protocol: TCP The Deployment:\napiVersion: apps/v1 kind: Deployment metadata: name: soft-serve namespace: soft-serve labels: app: soft-serve spec: replicas: 2 revisionHistoryLimit: 4 strategy: type: RollingUpdate rollingUpdate: maxSurge: 1 maxUnavailable: 0 selector: matchLabels: app: soft-serve template: metadata: labels: app: soft-serve spec: containers: - image: charmcli/soft-serve:latest name: soft-serve ports: - containerPort: 23231 name: ssh protocol: TCP securityContext: allowPrivilegeEscalation: false readOnlyRootFilesystem: true terminationMessagePath: /dev/termination-log terminationMessagePolicy: File volumeMounts: - mountPath: /soft-serve name: repos readOnly: true securityContext: runAsUser: 1000 runAsGroup: 1000 fsGroup: 1000 volumes: - name: repos hostPath: path: /soft-serve type: Directory In the Deployment we are setting some specific security context information to make it so the container is running as the user who owns the directory that has been mounted into the Kind node and which we are mounting into the Pod.\nWhen you install a Linux distribution and create the main user for that install it will likely have the id 1000 for the User and the Group, you can double check this by running the following commands in your terminal:\n❯ id # Prints the User ID, Group ID and IDs of other groups the user is part of uid=1000(nalum) gid=1000(nalum) groups=1000(nalum),3(sys),90(network),98(power),962(realtime),964(docker),991(lp),995(audio),998(wheel) ❯ id -u # Only the User ID 1000 ❯ id -g # Only the Group ID (this is the main group for this user) 1000 This was used earlier when we started Soft Serve with the docker command to set the user:group for the container to run as.\nLet\u0026rsquo;s apply these resources to the Kind cluster:\n❯ kubectl apply -f soft-serve.yaml namespace/soft-serve created service/git created deployment.apps/soft-serve created Now if you run the command to get the Pods in the created Namespace you should see something like the following:\n❯ kubectl -n soft-serve get pods NAME READY STATUS RESTARTS AGE soft-serve-786fb9c9f8-2h4pl 1/1 Running 0 12s soft-serve-786fb9c9f8-vzxgw 1/1 Running 0 12s Configure Soft Serve Configuring Soft Serve is pretty simple, go into the config repo we cloned earlier and edit the config.yaml file (cut down file for brevity):\n... host: git.soft-serve ... repos: ... - name: Flux repo: flux private: false note: \u0026#34;Flux Kind Cluster Demo running Soft Serve local git server\u0026#34; ... We\u0026rsquo;ve changed the host name and added a new repository to the config. To have this repository appear correctly and be used by Flux within the Kind cluster we need to create a symlink from ${PATH_TO_CODE}/flux in ${PATH_TO_CODE}/repos:\n❯ cd ${PATH_TO_CODE}/repos ❯ ls -lah total 12K drwxr-xr-x 3 nalum nalum 4.0K Feb 24 09:18 . drwxr-xr-x 13 nalum nalum 4.0K Feb 8 13:05 .. drwxr-xr-x 5 nalum nalum 4.0K Feb 8 13:12 config ❯ ln -s ../flux ./flux ❯ ls -lah total 12K drwxr-xr-x 3 nalum nalum 4.0K Feb 24 09:18 . drwxr-xr-x 13 nalum nalum 4.0K Feb 8 13:05 .. drwxr-xr-x 5 nalum nalum 4.0K Feb 8 13:12 config lrwxrwxrwx 1 nalum nalum 7 Feb 24 09:18 flux -\u0026gt; ../flux If you have the repo setup already with a README that should display when you view it in the SSH TUI, if you don\u0026rsquo;t have a repo setup let\u0026rsquo;s do a quick setup of git and add a README file to the flux repo, something simple e.g.:\n❯ cd flux ❯ git init Initialized empty Git repository in /home/nalum/code/flux/.git/ ❯ tee README.md \u0026lt;\u0026lt;EOT heredoc\u0026gt; # Flux Kind Cluster heredoc\u0026gt; heredoc\u0026gt; Flux GitRepository Source heredoc\u0026gt; EOT # Flux Kind Cluster Flux GitRepository Source ❯ cat README.md # Flux Kind Cluster Flux GitRepository Source ❯ git add README.md ❯ git commit -m \u0026#34;Adding README\u0026#34; [main (root-commit) b83b100] Adding README 1 file changed, 3 insertions(+) create mode 100644 README.md In order to see this change in the SSH TUI you will need to restart the docker container e.g. docker restart soft-serve. Now when you ssh into Soft Serve running on your local docker install you will see something like the following:\nThe same can be done with the instance running on the Kind Cluster. Restart the running Pods e.g. kubectl --context kind-dev -n soft-serve delete pods -l app=soft-serve. Once the Pods have been recreated you can port forward to one of the running Pods e.g. kubectl --context kind-dev -n soft-serve port-forward soft-serve-786fb9c9f8-25wkc 23232:23231 In the above command I\u0026rsquo;ve port forward the Pods port 23231 to the local port 23232. So now we can ssh into the TUI on the Pod and see the same view as above.\nIn the normal day to day use with Flux you do not need to stop and start the Soft Serve instances unless you want to use the TUI and see the README file updates as the TUI only appears to update when there is a push to the repo.\nSetting up Flux In the flux repo setup a structure like the following:\n❯ tree -a -I .git . ├── clusters │ └── dev │ └── flux-system └── README.md We are going to export the Flux installation into the flux-system directory, you can do this as follows: flux install --export \u0026gt; clusters/dev/flux-system/gotk-components.yaml\nI won\u0026rsquo;t include the content of that file as there is a lot in it, but feel free to browse. Next we\u0026rsquo;ll want to create a gotk-sync.yaml and a kustomization.yaml. Which you can do as follows:\n❯ flux create source git flux-system \\ --git-implementation=libgit2 \\ --url=ssh://git@git.soft-serve:23231/flux.git \\ --branch=main \\ --interval=1m \\ --export \u0026gt; clusters/dev/flux-system/gotk-sync.yaml ❯ flux create kustomization flux-system \\ --source=GitRepository/flux-system \\ --path=./clusters/dev \\ --prune=true \\ --interval=1m \\ --export \u0026gt;\u0026gt; clusters/dev/flux-system/gotk-sync.yaml ❯ cd clusters/dev/flux-system ❯ kustomize create --autodetect ❯ cd ../../.. ❯ tree -a -I .git -I vendor . ├── clusters │ └── dev │ └── flux-system │ ├── gotk-components.yaml │ ├── gotk-sync.yaml │ └── kustomization.yaml └── README.md It is also worth adding the resource above that created the Soft Serve deployment we are using and setting up the kustomization.yaml for that directory:\n❯ tree -a -I .git . ├── clusters │ └── dev │ ├── flux-system │ │ ├── gotk-components.yaml │ │ ├── gotk-sync.yaml │ │ └── kustomization.yaml │ └── soft-serve │ ├── deployment.yaml │ ├── kustomization.yaml │ ├── namespace.yaml │ └── service.yaml └── README.md Now let\u0026rsquo;s apply the above flux-system resources to the Kind cluster:\n❯ kubectl apply -f clusters/dev/flux-system/gotk-components.yaml namespace/flux-system created customresourcedefinition.apiextensions.k8s.io/alerts.notification.toolkit.fluxcd.io created customresourcedefinition.apiextensions.k8s.io/buckets.source.toolkit.fluxcd.io created customresourcedefinition.apiextensions.k8s.io/gitrepositories.source.toolkit.fluxcd.io created customresourcedefinition.apiextensions.k8s.io/helmcharts.source.toolkit.fluxcd.io created customresourcedefinition.apiextensions.k8s.io/helmreleases.helm.toolkit.fluxcd.io created customresourcedefinition.apiextensions.k8s.io/helmrepositories.source.toolkit.fluxcd.io created customresourcedefinition.apiextensions.k8s.io/kustomizations.kustomize.toolkit.fluxcd.io created customresourcedefinition.apiextensions.k8s.io/providers.notification.toolkit.fluxcd.io created customresourcedefinition.apiextensions.k8s.io/receivers.notification.toolkit.fluxcd.io created serviceaccount/helm-controller created serviceaccount/kustomize-controller created serviceaccount/notification-controller created serviceaccount/source-controller created clusterrole.rbac.authorization.k8s.io/crd-controller-flux-system created clusterrolebinding.rbac.authorization.k8s.io/cluster-reconciler-flux-system created clusterrolebinding.rbac.authorization.k8s.io/crd-controller-flux-system created service/notification-controller created service/source-controller created service/webhook-receiver created deployment.apps/helm-controller created deployment.apps/kustomize-controller created deployment.apps/notification-controller created deployment.apps/source-controller created networkpolicy.networking.k8s.io/allow-egress created networkpolicy.networking.k8s.io/allow-scraping created networkpolicy.networking.k8s.io/allow-webhooks created Before we apply the sync file we need to setup a known_hosts file and an SSH Key that Flux can work with in order to pull from our Soft Serve repo. Let\u0026rsquo;s start with the SSH Key:\n❯ ssh-keygen -t ed25519 -C \u0026#34;flux-system\u0026#34; Generating public/private ed25519 key pair. Enter file in which to save the key (/home/nalum/.ssh/id_ed25519): /home/nalum/code/ssh/identity ... +----[SHA256]-----+ To create the known_hosts file we need to get the public key of the Soft Serve server we\u0026rsquo;re running, we can do that with:\n❯ cat ${PATH_TO_CODE}/ssh/soft_serve_server_ed25519.pub ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIMDYacTjeLH4ha6BDgWN3rXeh70GDYmaSVBw5UQg1FQ3 root@2dcd99be9aef Copy this public key into a new ${PATH_TO_CODE}/ssh/known_hosts file and put the domain name in front of it something like the following:\ngit.soft-serve:23231 ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIMDYacTjeLH4ha6BDgWN3rXeh70GDYmaSVBw5UQg1FQ3 root@2dcd99be9aef Now that we have the SSH Key and the known_hosts file we need to create a secret that Flux will pick up, you can use -o yaml to see the output:\n❯ kubectl -n flux-system create secret generic \\ --from-file=identity=${PATH_TO_CODE}/ssh/identity \\ --from-file=identity.pub=${PATH_TO_CODE}/ssh/identity.pub \\ --from-file=known_hosts=${PATH_TO_CODE}/ssh/known_hosts \\ flux-system secret/flux-system created With that put in place we can then apply the sync file:\n❯ kubectl apply -f clusters/dev/flux-system/gotk-sync.yaml gitrepository.source.toolkit.fluxcd.io/flux-system created kustomization.kustomize.toolkit.fluxcd.io/flux-system created If you now run flux get all you should see something like the following:\n❯ flux get all NAME READY MESSAGE REVISION SUSPENDED gitrepository/flux-system True Fetched revision: main/7e12f0c main/7e12f0c False NAME READY MESSAGE REVISION SUSPENDED kustomization/flux-system False kustomization path not found: stat /tmp/flux-system2367946620/clusters/dev: no such file or directory False The Kustomization is not working here because we have not committed any of the files to the repo yet. If you run watch flux get all --all-namespaces and the add and commit the clusters folder and it\u0026rsquo;s contents, you will see the Kustomization reconcile itself:\n❯ flux get all --all-namespaces NAMESPACE NAME READY MESSAGE REVISION SUSPENDED flux-system gitrepository/flux-system True Fetched revision: main/b6e77db main/b6e77db False NAMESPACE NAME READY MESSAGE REVISION SUSPENDED flux-system kustomization/flux-system True Applied revision: main/b6e77db main/b6e77db False If you describe the kustomization object with kubectl you\u0026rsquo;ll see the resources that have been applied to the system through it:\n❯ kubectl -n flux-system describe kustomizations.kustomize.toolkit.fluxcd.io flux-system Name: flux-system Namespace: flux-system Labels: kustomize.toolkit.fluxcd.io/name=flux-system kustomize.toolkit.fluxcd.io/namespace=flux-system Annotations: \u0026lt;none\u0026gt; API Version: kustomize.toolkit.fluxcd.io/v1beta2 Kind: Kustomization Metadata: ... Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning error 6m35s kustomize-controller kustomization path not found: stat /tmp/flux-system1699096295/clusters/dev: no such file or directory ... Normal info 115s kustomize-controller CustomResourceDefinition/alerts.notification.toolkit.fluxcd.io configured CustomResourceDefinition/buckets.source.toolkit.fluxcd.io configured ... Namespace/flux-system configured Namespace/soft-serve configured ServiceAccount/flux-system/helm-controller configured ServiceAccount/flux-system/kustomize-controller configured ... Deployment/flux-system/source-controller configured Deployment/soft-serve/soft-serve configured ... Normal info 34s kustomize-controller Reconciliation finished in 680.646597ms, next run in 1m0s Final Thoughts This is a lot of work in order to use Flux from a local repository. This was a fun exercise to get going and document here. It could be automated and be a single command to setup the whole system, which maybe is worth it. I\u0026rsquo;ll leave that for you to decide.\nPlease leave a comment with your thoughts or if you have any issues following along I\u0026rsquo;d be happy to try helping out.\n","permalink":"https://luke.mallon.ie/posts/2022-02/flux-with-kind-and-soft-serve/","summary":"Originally post to hackmd.io\nThis article covers getting a local Kind cluster setup with Flux and the self hosted git server Soft Serve.\nRequirements You will need to have the following installed:\ndocker installation kubectl installation kustomize installation flux installation kind installation soft installation Assumptions I am assuming the following things:\nRunning on Linux Familiar with: Docker YAML Git Kind kubectl Let\u0026rsquo;s get Started We need to run two copies of Soft Serve in order to be able to access and configure the software.","title":"Flux with Kind and Soft Serve"},{"content":"I\u0026rsquo;m going to run through what is needed to get Kubernetes running on a cluster of Raspberry Pi 3 machines. Thankfully with the addition of kubeadm this has become fairly trivial. The getting started guide for kubeadm can give you more information about the tool itself, I\u0026rsquo;ll outline the steps here but feel free to go to that getting started guide.\nThere are a few blog posts out there that discuss doing this and suggest using hypriot (because docker didn\u0026rsquo;t officially support the arm architecture) as the OS to use. I\u0026rsquo;m going to do this with Raspbian Jessie Lite (because docker now officially supports the arm architecture) which can be downloaded here. I\u0026rsquo;m running Debian so the commands will work for the majority of Linux systems.\nYou can setup a single node or multi-node cluster of Pi. The Pi 3 is recommended because it comes with 1GB of RAM which leaves you more RAM to run your own systems on the cluster than the 512MB version.\nTo get started you\u0026rsquo;ll need to have an SD Card (I\u0026rsquo;ve used 64GB cards without issue) and load the Raspbian Jessie Lite image onto the card. You can do this using the dd command. First let\u0026rsquo;s make sure we\u0026rsquo;re using the right device on the system as we don\u0026rsquo;t want to overwrite our OS drive.\n$ df -h # This command is showing mounted volumes, you should see your sdcard listed here. Filesystem Size Used Avail Use% Mounted on /dev/sda1 8.2G 7.0G 801M 90% / udev 10M 0 10M 0% /dev tmpfs 3.2G 9.2M 3.2G 1% /run tmpfs 7.9G 507M 7.4G 7% /dev/shm tmpfs 5.0M 4.0K 5.0M 1% /run/lock tmpfs 7.9G 0 7.9G 0% /sys/fs/cgroup /dev/sda2 237M 42M 183M 19% /boot tmpfs 1.6G 56K 1.6G 1% /run/user/1000 /dev/sdb 64G 0 64G 0% /mnt/nalum/sd In this we can see that there are 3 mounted partitions for me, the drive I\u0026rsquo;m looking for is /dev/sdb. For you this could be something like /dev/mmcblk0. If you see sdb1 rather than sdb you\u0026rsquo;ll want to remove the digit or in the case of mmcblk0p1 you\u0026rsquo;ll want to remove the p1. We can double check that this is correct by running the command ls -lah /dev/mmcblk0* this will result in something like the following output:\n$ ls -lah /dev/mmcblk0* brw-rw---- 1 root disk 8, 0 Dec 15 09:43 /dev/mmcblk0 brw-rw---- 1 root disk 8, 1 Dec 15 09:43 /dev/mmcblk0p1 As you can see we have mmcblk0 and mmcblk0p1, mmcblk0 is the whole device and mmcblk0p1 is a partition on that device, there can be multiple partitions and there will be two after the Raspbian image is applied to the SDCard. We apply the Raspbian image to the SD card by using the following command:\nNOTE\nThis command will replace the contents of a drive (HDD, SSD, SDCard, etc), be absolutely certain that you are running it against the correct drive.\n$ sudo dd bs=4M if=/path/to/raspbian.image of=/dev/sdb $ sync The Raspberry Pi site notes that if bs=4M doesn\u0026rsquo;t work change it to bs=1M and that it will take longer with that setting. Running sync will make sure that it is safe to unmount the SD Card. Check here for full installation instructions for Linux, Mac OS and Windows.\nThe next step is to boot the Raspberry Pi using the SD Cards you\u0026rsquo;ve setup. You will need to plug a monitor and keyboard directly into at least one Pi as SSH has been disabled by default on the Raspbian since November 2016.\nThe following set of commands need to be run on each of the Raspbian installs. They will install any available updates, vim, docker and kubernetes and make changes to some files enabling ssh and setting a cgroup config for kubernetes/docker.\n$ sudo su $ apt-get update $ apt-get upgrade -y $ apt-get install -y vim $ vim /etc/hostname ## Replace contents with kubenode[0-9]{2,} So if you run cat /etc/hostname you should see something like the following: kubenode00\n$ touch /boot/ssh $ vim /boot/cmdline.txt ## Add `cgroup_enable=cpuset` before `elevator=deadline` If you run cat /boot/cmdline.txt you should see something like the following:\ndwc_otg.lpm_enable=0 console=serial0,115200 console=tty1 root=/dev/mmcblk0p2 rootfstype=ext4 cgroup_enable=cpuset elevator=deadline fsck.repair=yes rootwait quiet init=/usr/lib/raspi-config/init_resize.sh Now we will install docker and kubernetes and reboot:\nNOTE\nThe first curl command can be very dangerous, 1) because we ran sudo su at the beginning of this and 2) because you don\u0026rsquo;t know what is in the file you piped into sh. So I very much recommend that you download the file and have a look at what it is doing to make sure you are happy running it.\n$ curl -sSL https://get.docker.com | sh $ curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add - $ echo \u0026#34;deb http://apt.kubernetes.io/ kubernetes-xenial main\u0026#34; \u0026gt; /etc/apt/sources.list.d/kubernetes.list $ apt-get update $ apt-get install -y kubelet kubeadm kubectl kubernetes-cni $ reboot now The following set of commands should be run on one Raspbian install which will setup the master Kubernetes node:\n$ sudo su $ kubeadm init --pod-network-cidr=10.244.0.0/16 --use-kubernetes-version=v1.5.2 $ curl -sSL \u0026#34;https://github.com/coreos/flannel/blob/master/Documentation/kube-flannel.yml?raw=true\u0026#34; | sed \u0026#34;s/amd64/arm/g\u0026#34; | kubectl create -f - The kubeadm init command will produce output like the following:\n[kubeadm] WARNING: kubeadm is in alpha, please do not use it for production clusters. [preflight] Running pre-flight checks [init] Using Kubernetes version: v1.5.1 [tokens] Generated token: \u0026lt;token\u0026gt; [certificates] Generated Certificate Authority key and certificate. [certificates] Generated API Server key and certificate [certificates] Generated Service Account signing keys [certificates] Created keys and certificates in \u0026#34;/etc/kubernetes/pki\u0026#34; [kubeconfig] Wrote KubeConfig file to disk: \u0026#34;/etc/kubernetes/kubelet.conf\u0026#34; [kubeconfig] Wrote KubeConfig file to disk: \u0026#34;/etc/kubernetes/admin.conf\u0026#34; [apiclient] Created API client, waiting for the control plane to become ready [apiclient] All control plane components are healthy after 61.317580 seconds [apiclient] Waiting for at least one node to register and become ready [apiclient] First node is ready after 6.556101 seconds [apiclient] Creating a test deployment [apiclient] Test deployment succeeded [token-discovery] Created the kube-discovery deployment, waiting for it to become ready [token-discovery] kube-discovery is ready after 6.020980 seconds [addons] Created essential addon: kube-proxy [addons] Created essential addon: kube-dns Your Kubernetes master has initialized successfully! You should now deploy a pod network to the cluster. Run \u0026#34;kubectl apply -f [podnetwork].yaml\u0026#34; with one of the options listed at: http://kubernetes.io/docs/admin/addons/ You can now join any number of machines by running the following on each node: kubeadm join --token=\u0026lt;token\u0026gt; \u0026lt;master-ip\u0026gt; The curl command run will setup flannel on the cluster which is required to allow the pods to talk to each other. There are other options that you can use instead of flannel if you want.\nYou need to note the kubeadm join command at the bottom of the output as you will need it for the other nodes. The last step in setup of the cluster is to add the other nodes which you can do by running the noted kubeadm join command on each of the other Raspberry Pi:\n$ sudo su $ kubeadm join --token=a123c6.d61342c6501bf2c8 192.168.168.210 With the above command run on each of the nodes you should start to see them show in the output of kubectl get nodes, you can run this on the master node and you should see something like the following:\n$ kubectl get nodes NAME STATUS AGE kubemaster Ready,master 2m kubenode01 Ready 2m kubenode02 Ready 2m To be able to control the cluster from any machine, not just the master, copy the file /etc/kubernetes/admin.conf from the master node to any other machine that you want to be able to access the cluster from. This can be combined with your existing kubectl config or you can have kubectl look at the file separate to your config by using the flag --kubeconfig.\nSo with that done you now have a Kubernetes cluster running on your Raspberry Pi. I haven\u0026rsquo;t really done anything more with my cluster since setting it up but feel free to ask questions and I\u0026rsquo;ll do my best to answer. I think the next thing I\u0026rsquo;ll be doing is setting up CephFS or NFS to act as persistent storage for the cluster.\n","permalink":"https://luke.mallon.ie/posts/2017-02/kuberrypi/","summary":"I\u0026rsquo;m going to run through what is needed to get Kubernetes running on a cluster of Raspberry Pi 3 machines. Thankfully with the addition of kubeadm this has become fairly trivial. The getting started guide for kubeadm can give you more information about the tool itself, I\u0026rsquo;ll outline the steps here but feel free to go to that getting started guide.\nThere are a few blog posts out there that discuss doing this and suggest using hypriot (because docker didn\u0026rsquo;t officially support the arm architecture) as the OS to use.","title":"KuBerryPi"},{"content":"I made the decision a while ago that I wanted to get a mechanical keyboard, so I started to look into it and found that there is quite a lot going on in that area of keyboards.\nMy first stop was to search using Google and see what I could find. It showed me quite a few sites which appeared good: Mechanical Keyboards, Code Keyboards and WASD Keyboards (who make Code Keyboards) to name some, but the most useful link it gave me was to the Reddit community /r/MechanicalKeyboards. There are some fantastic resources available in the wiki for that subreddit (switch guides as an example) and the people are nice and keen to help where they can.\nUsing /r/MechanicalKeyboards I was able to see many examples of keyboards and custom keyboards and work out what it was I wanted from my own. Being a developer I spend a lot of time using a keyboard and I wanted something that was ergonomic but allowed me to define the layout of the keys.\nThe first one I looked at was the Code Keyboard as it was co-created by Jeff Atwood and while it did allow for multiple layouts and the ability to disable certain keys, it wasn\u0026rsquo;t as flexible as I wanted and it isn\u0026rsquo;t really ergonomic. After all it is the traditional size and shape of keyboard.\nSo I kept looking around and found many keyboards of all shapes and sizes. Some of them interested me and some of them looked a bit much. The one that interested me the most was the Ergodox (not linking to the official site as it seems like they lost control of the domain). A keyboard designed by enthusiasts and open sourced for anyone to build. As you might expect, looking around for an off the shelf version didn\u0026rsquo;t turn up anything. There are two places, I found, where you can get it: Massdrop and ergodox-ez which both supply a kit so you can build the keyboard yourself. I wasn\u0026rsquo;t sure I wanted to go down that route, so I decided to keep looking.\nIn looking around I saw some really nice keyboards but nothing that grabbed me the way the Ergodox did.\nThen I stumbled across the Infinity Ergodox, created by input.club as a fork of the Ergodox, it offers some improvements over the original design.\nThe goals for the Infinity ErgoDox were the most complex objectives in any modern keyboard we know of.\nOpen Source Design No Upfront Tooling Costs Fully Programmable Keys Split Keyboard Functionality LED Control Screen Infinite Layers in each Half Reading about the keyboard on the official site persuaded me to go for it, both halves of the keyboard are fully functional on their own and fully programmable. It is only possible (as of this posting) to buy on massdrop.\nThis research also introduced me to the different layouts that have formed over the years of the typewriter and keyboard and the history of both. The qwerty layout was formed for physical reasons. The keys of the typewriter would jam as people typed, which caused the creators of the Sholes and Glidden typewriter to try to find the optimal layout that would allow people to type at a higher speeds without jamming the keys. Not to say it didn\u0026rsquo;t have its own issues. So qwerty, designed over a century ago for a typewriter, still in use on keyboards, mechanical and non-mechanical alike, where the reasons for its existence no longer exist, I figured it would be a good time to check out alternative layouts.\nAfter some searching and reading up on layouts. I decided that I would start using the Dvorak layout and have switched my phones keyboard over to it. But more specifically for my Ergodox I decided to switch to a variant of Dvorak, Programmers Dvorak.\nSo with that research and decision made I bought it. Then I had to wait… and wait. Until finally it was delivered.\nBefore starting in on putting it together I decided to get some practice in with soldering as I hadn\u0026rsquo;t done any in at least 15 years. It took a bit to get into it again and with some help from my parents who both have experience with it, I was able to get going.\nSo I started putting it together. I went with the 65g Zealio switches and a blank, clear DCS keycap set. To get an idea of how it looked put together I loosely built it, without the PCB in place and without removing the protective paper from the clear plastic casing. I also opted to get the extended hand rests for my build.\nIt looks and feels nice and I can\u0026rsquo;t wait to get started building it properly. So I get out the things I need and I take apart the keyboard and end up with this.\nNext I put the PCB on the switch mounting plate and apply some pressure to get the switches in place on the PCB.\nThen I solder each of the currently mounted switches so the PCB is firmly in place and will stay there while the rest of the switches are mounted.\nSo I go through all the switches and mount them to the Plate and PCB and solder them in place.\nThen we test the keyboard to make sure it is all working as expected. But it\u0026rsquo;s not. I open a text editor on my laptop and plugin the keyboard and start pressing the keys. Some of the keys are fine and work as expected some of them fire when I touch the key, not applying any pressure, just touching the key. Thanks to /r/MechanicalKeyboards I was able to find out that the switches I went with can have this problem called chatter and that there is a fairly easy fix for it.\nThe problem that causes chatter is when the two contacts, one stationary and one which moves when the key is pressed, in the switch are touching when the key is in its resting position, i.e. not pressed, or touch earlier than they should. To fix the problem, requires that you remove the top of the switch and apply some pressure to the stationary contact slightly bending it towards the center of the switch and then reassembling the switch.\nYou can test the switch using a multimeter to see that it is working correctly. So using the multimeter I was able to check exactly which switches were having trouble with chatter and then using 3 hair pins I was able to remove the top of the switch casing and adjust the stationary contact using a small screw driver.\nI fixed all the affected switches and tested again on my laptop and all was good, no chatter and the keys worked as expected. I believe Zealpc have sorted this issue for the next round of switches and that it is expected to run this January (2017). This had to be done to both halves of the keyboard.\nI am very pleased with how this turned out and am excited to start using my new Ergodox. It will take some time to get used to because it\u0026rsquo;s pyshically a new keyboard layout but also because I\u0026rsquo;m switching to a new character layout. I had a lot of fun putting this together and recommend to those interested that you go for it. Obviously it doesn\u0026rsquo;t have to be an Ergodox, what ever you choose to go with whether it\u0026rsquo;s 40%, 60% or the full 105 key keyboard, doing the research, purchasing and finally putting it together are all part of the fun and even if there are issues, like the chattering issue with Zealio, that can add to the fun if you let it \u0026#x1f600;.\n","permalink":"https://luke.mallon.ie/posts/2016-10/mechanical-keyboard/","summary":"I made the decision a while ago that I wanted to get a mechanical keyboard, so I started to look into it and found that there is quite a lot going on in that area of keyboards.\nMy first stop was to search using Google and see what I could find. It showed me quite a few sites which appeared good: Mechanical Keyboards, Code Keyboards and WASD Keyboards (who make Code Keyboards) to name some, but the most useful link it gave me was to the Reddit community /r/MechanicalKeyboards.","title":"Mechanical Keyboard"},{"content":"This is a website where I will be putting up information about different subjects that are of interest to me now and may be needed at points in the future. Mostly it will be things of a computer related nature.\nCurrently there is no tracking on this site and I do not make use of Cookies.\nThe theme toggle between light and dark makes use of the browser local storage, by default the dark theme is used and if you choose to switch a key=value pair will be created with the following data perf-theme=light. Each time you change the theme the value will change between light and dark.\nutteranc.es also adds a local storage key=value that is used to maintain your session with GitHub allowing you to comment on any of the content on this website. The key for this is utterances-session and the value will be your session id if you have logged in to GitHub with the comment system.\n","permalink":"https://luke.mallon.ie/about/","summary":"This is a website where I will be putting up information about different subjects that are of interest to me now and may be needed at points in the future. Mostly it will be things of a computer related nature.\nCurrently there is no tracking on this site and I do not make use of Cookies.\nThe theme toggle between light and dark makes use of the browser local storage, by default the dark theme is used and if you choose to switch a key=value pair will be created with the following data perf-theme=light.","title":"About"}]